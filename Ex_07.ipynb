{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQSzhxBvOQjb+eEZAeW2rU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adithya-Siddam/Ex-7-AAI/blob/main/Ex_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayC2DTnyfQYM",
        "outputId": "cfaaeae3-1cc9-4d61-da72-e9ff83e0f238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Origina1 Text: \n",
            "\n",
            "  Within each of us lies a remarkable potential. It may feel shrouded by\n",
            "   self-doubt or buried beneath challenges, but it's there, waiting to be \n",
            "   ignited. The key is to embrace the journey, with all its stumbles and \n",
            "   triumphs. Every mistake holds a lesson, and every obstacle overcome builds \n",
            "   resilience. So take a deep breath, believe in your ability to grow, and \n",
            "   chase the dreams that set your soul on fire.\n",
            "\n",
            " \n",
            "Summary : \n",
            "So take a deep breath, believe in your ability to grow, and \n",
            "   chase the dreams that set your soul on fire. Every mistake holds a lesson, and every obstacle overcome builds \n",
            "   resilience. It may feel shrouded by\n",
            "   self-doubt or buried beneath challenges, but it's there, waiting to be \n",
            "   ignited.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download( 'punkt' )\n",
        "nltk.download( 'stopwords' )\n",
        "def preprocess_text(text):\n",
        "\t# Tokenize the text into words\n",
        "\twords = word_tokenize(text)\n",
        "\t# Remove stopwords and punctuation\n",
        "\tstop_words= set(stopwords.words( 'english'))\n",
        "\tfiltered_words= [word for word in words if word. lower() not in stop_words and word.isalnum()]\n",
        "\n",
        "\t# Stemming\n",
        "\tstemmer = PorterStemmer()\n",
        "\n",
        "\tstemmed_words= [stemmer. stem(word) for word in filtered_words]\n",
        "\treturn stemmed_words\n",
        "def generate_summary(text,num_sentences=3):\n",
        "\n",
        "\tsentences= sent_tokenize(text)\n",
        "\tpreprocessed_text = preprocess_text(text)\n",
        "\t# Calculate the frequency of each word\n",
        "\tword_frequencies =nltk. FreqDist (preprocessed_text)\n",
        "\n",
        "\t# Calculate the score for each sentence based on word frequency\n",
        "\tsentence_scores ={}\n",
        "\tfor sentence in sentences:\n",
        "\t\tfor word, freq in word_frequencies.items():\n",
        "\t\t\tif word in sentence.lower():\n",
        "\t\t\t\tif sentence not in sentence_scores:\n",
        "\t\t\t\t\tsentence_scores[sentence] = freq\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tsentence_scores[sentence]+= freq\n",
        "\t# Select top N sentences with highest scores\n",
        "\tsummary_sentences= sorted(sentence_scores, key=sentence_scores.get,reverse=True) [ : num_sentences]\n",
        "\n",
        "\treturn ' '. join(summary_sentences)\n",
        "if __name__==\"__main__\":\n",
        "\tinput_text =\"\"\"\n",
        "  Within each of us lies a remarkable potential. It may feel shrouded by\n",
        "   self-doubt or buried beneath challenges, but it's there, waiting to be\n",
        "   ignited. The key is to embrace the journey, with all its stumbles and\n",
        "   triumphs. Every mistake holds a lesson, and every obstacle overcome builds\n",
        "   resilience. So take a deep breath, believe in your ability to grow, and\n",
        "   chase the dreams that set your soul on fire.\n",
        "\"\"\"\n",
        "summary = generate_summary(input_text)\n",
        "print(\"Origina1 Text: \")\n",
        "print (input_text )\n",
        "print( \" \\nSummary : \" )\n",
        "print(summary)"
      ]
    }
  ]
}